{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing MNIST digit recognition in tensorflow without using Keras API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "%colors nocolor\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Simple Dense Class \n",
    "\n",
    "Dense layer implements the following input transformation, where W and b are model parameters, and activation is an element-wise function (usually relu, but it would be softmax for the last layer):\n",
    "\n",
    "       output = activation(dot(W, input) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing simple Python class, NaiveDense, \n",
    "# that creates two TensorFlow variables, W and b, \n",
    "# and exposes a __call__() method that applies the preceding transformation\n",
    "\n",
    "class NaiveDense:\n",
    "    def __init__(self, input_size , output_size , activation ):\n",
    "        self.activation = activation\n",
    "        \n",
    "        # Create a matrix, W, of shape (input_size, output_size), initialized with random values.\n",
    "        w_shape = (input_size, output_size)\n",
    "        w_initial_value = tf.random.uniform(w_shape, minval=0, maxval=1e-1)\n",
    "        self.W = tf.Variable(w_initial_value)\n",
    "        \n",
    "        # Create a vector, b, of shape (output_size,), initialized with zeros.\n",
    "        b_shape = (output_size,)\n",
    "        b_intial_value = tf.zeros(b_shape)\n",
    "        self.b = tf.Variable(b_intial_value)\n",
    "        \n",
    "    # Applying the forward pass    \n",
    "    def __call__(self, inputs):\n",
    "        return self.activation(tf.matmul(inputs, self.W) + self.b)\n",
    "    \n",
    "    @property\n",
    "    # Convenience method for retrieving the layer’s weights\n",
    "    def weights(self):\n",
    "        return [self.W, self.b]\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple Sequential Class\n",
    " \n",
    " Create a NaiveSequential class to chain these layers. It wraps a list of layers and exposes a __call__() method that simply calls the underlying layers on the inputs, in order. It also features a weights property to easily keep track of the layers’ parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveSequential:\n",
    "    def __init__(self,layers) :\n",
    "        self.layers = layers\n",
    "        \n",
    "    def __call__(self,inputs):\n",
    "        x = inputs \n",
    "        for layer in self.layers :\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    @property\n",
    "    def weights(self):\n",
    "        weights = []\n",
    "        for layer in self.layers:\n",
    "            weights += layer.weights \n",
    "        return weights \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using this NaiveDense class and this NaiveSequential class, we can create a mock \n",
    "# Keras model:\n",
    "\n",
    "model = NaiveSequential([\n",
    "    NaiveDense(input_size=28*28, output_size=512, activation=tf.nn.relu),\n",
    "    NaiveDense(input_size=512, output_size=10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "assert len(model.weights) == 4\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Generator\n",
    "\n",
    "A way to iterate over the MNIST data in mini-batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class BatchGenerator:\n",
    "    def __init__(self, images, labels, batch_size = 128):\n",
    "        assert len(images) == len(labels)\n",
    "        self.index = 0\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.num_batches = math.ceil(len(images)/batch_size)\n",
    "        \n",
    "    def next(self):\n",
    "        images = self.images[self.index : self.index + self.batch_size]\n",
    "        labels = self.labels[self.index : self.index + self.batch_size]\n",
    "        self.index += self.batch_size\n",
    "        return images, labels         "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running one training step\n",
    "\n",
    "The “training step”: updating the weights of the model after running it on one batch of data. We need to\n",
    "1.  Compute the predictions of the model for the images in the batch.\n",
    "2.  Compute the loss value for these predictions, given the actual labels.\n",
    "3.  Compute the gradient of the loss with regard to the model’s weights.\n",
    "4.  Move the weights by a small amount in the direction opposite to the gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  compute the gradient, we will use the TensorFlow GradientTape object\n",
    "\n",
    "def one_training_step(model, images_batch, labels_batch):\n",
    "    # Run the “forward pass” (compute the model’s predictions under a GradientTape scope)\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images_batch)\n",
    "        per_sample_losses = tf.keras.losses.sparse_categorical_crossentropy(labels_batch,predictions)\n",
    "        average_loss = tf.reduce_mean(per_sample_losses)\n",
    "    \n",
    "    # Compute the gradient of the loss with regard to the weights. The output gradients\n",
    "    # is a list where each entry corresponds to a weight from the model.weights list.\n",
    "    gradients = tape.gradient(average_loss, model.weights)\n",
    "    \n",
    "    # Update the weights using the gradients\n",
    "    update_weights(gradients, model.weights)\n",
    "    return average_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating the weights \n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "def update_weights(gradients, weights ):\n",
    "    for g, w in zip(gradients, weights):\n",
    "        # assign_sub is the equivalent of -= for TensorFlow variables.\n",
    "        w.assign_sub(g * learning_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A full training loop \n",
    "\n",
    "An epoch of training simply consists of repeating the training step for each batch in the training data, and the full training loop is simply the repetition of one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, images, labels, epochs, batch_size = 128):\n",
    "    for epoch_counter in range(epochs):\n",
    "        print(F\"Epoch {epoch_counter}\")\n",
    "        batch_generator = BatchGenerator(images, labels)\n",
    "        for batch_counter in range(batch_generator.num_batches):\n",
    "            images_batch , labels_batch = batch_generator.next()\n",
    "            loss = one_training_step(model, images_batch, labels_batch)\n",
    "            if batch_counter % 100 == 0:\n",
    "                print(F\"loss at batch {batch_counter}: {loss: .2f}\")\n",
    "                \n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TestDrive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "loss at batch 0:  6.95\n",
      "loss at batch 100:  2.26\n",
      "loss at batch 200:  2.22\n",
      "loss at batch 300:  2.12\n",
      "loss at batch 400:  2.26\n",
      "Epoch 1\n",
      "loss at batch 0:  1.94\n",
      "loss at batch 100:  1.90\n",
      "loss at batch 200:  1.84\n",
      "loss at batch 300:  1.74\n",
      "loss at batch 400:  1.86\n",
      "Epoch 2\n",
      "loss at batch 0:  1.61\n",
      "loss at batch 100:  1.59\n",
      "loss at batch 200:  1.51\n",
      "loss at batch 300:  1.45\n",
      "loss at batch 400:  1.52\n",
      "Epoch 3\n",
      "loss at batch 0:  1.35\n",
      "loss at batch 100:  1.35\n",
      "loss at batch 200:  1.25\n",
      "loss at batch 300:  1.23\n",
      "loss at batch 400:  1.28\n",
      "Epoch 4\n",
      "loss at batch 0:  1.15\n",
      "loss at batch 100:  1.16\n",
      "loss at batch 200:  1.05\n",
      "loss at batch 300:  1.06\n",
      "loss at batch 400:  1.11\n",
      "Epoch 5\n",
      "loss at batch 0:  0.99\n",
      "loss at batch 100:  1.02\n",
      "loss at batch 200:  0.91\n",
      "loss at batch 300:  0.94\n",
      "loss at batch 400:  0.98\n",
      "Epoch 6\n",
      "loss at batch 0:  0.88\n",
      "loss at batch 100:  0.91\n",
      "loss at batch 200:  0.80\n",
      "loss at batch 300:  0.84\n",
      "loss at batch 400:  0.90\n",
      "Epoch 7\n",
      "loss at batch 0:  0.80\n",
      "loss at batch 100:  0.82\n",
      "loss at batch 200:  0.72\n",
      "loss at batch 300:  0.77\n",
      "loss at batch 400:  0.83\n",
      "Epoch 8\n",
      "loss at batch 0:  0.73\n",
      "loss at batch 100:  0.75\n",
      "loss at batch 200:  0.66\n",
      "loss at batch 300:  0.72\n",
      "loss at batch 400:  0.78\n",
      "Epoch 9\n",
      "loss at batch 0:  0.68\n",
      "loss at batch 100:  0.70\n",
      "loss at batch 200:  0.61\n",
      "loss at batch 300:  0.67\n",
      "loss at batch 400:  0.73\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28*28))\n",
    "train_images = train_images.astype(\"float32\")/255\n",
    "test_images = test_images.reshape((10000, 28*28))\n",
    "test_images = test_images.astype(\"float32\")/255\n",
    "\n",
    "fit(model, train_images, train_labels, epochs=10, batch_size=128)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)\n",
    "len(train_images)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Evaluate the model by taking the argmax of its predictions over the test images, and comparing it to the expected labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  0.815\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "predictions = model(test_images)\n",
    "predictions = predictions.numpy() # Calling .numpy() on a TensorFlow tensor converts it to a NumPy tensor.\n",
    "predicted_labels = np.argmax(predictions,axis=1)\n",
    "matches = predicted_labels == test_labels\n",
    "print(F\"accuracy : {matches.mean(): .3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
